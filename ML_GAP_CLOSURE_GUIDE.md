# ML Gap Closure Prediction Guide

## Overview

Machine learning model to predict gap closure likelihood using XGBoost/Random Forest with comprehensive feature engineering.

## Model Features

### Member Characteristics
- Age, gender, risk score
- Chronic conditions count
- Prior year compliance
- Member tenure
- Socioeconomic factors (zip code, education)

### Clinical Factors
- Measure type (preventive vs chronic care)
- Gap severity
- Time since last visit
- Assigned PCP characteristics
- Distance to facilities

### Engagement Factors
- Portal usage frequency
- Response rate to outreach
- Appointment no-show history
- Preferred contact channel
- Best contact time

### Operational Factors
- Coordinator workload
- Intervention type
- Season/time of year
- Days until deadline

## Model Training

### Training Process

1. **Data Preparation**:
   ```python
   from utils.ml_model_training import train_model
   
   metrics = train_model(
       model_type='xgboost',
       n_samples=10000,
       output_path='models/gap_closure_model.pkl'
   )
   ```

2. **Feature Engineering**:
   - Extract all feature groups
   - Handle missing values
   - Encode categorical variables
   - Scale numerical features

3. **Model Training**:
   - XGBoost or Random Forest
   - Handle class imbalance (SMOTE)
   - Cross-validation (5-fold)
   - Feature importance analysis

4. **Evaluation**:
   - Accuracy, Precision, Recall, F1
   - ROC AUC
   - Confusion matrix
   - Success rate by probability bucket

### Training Script

```bash
python utils/ml_model_training.py --model-type xgboost --n-samples 10000 --output models/gap_closure_model.pkl
```

## Model Output

### Prediction Results

- **Closure Probability**: 0-100%
- **Confidence Interval**: Lower and upper bounds
- **Key Influencing Factors**: Top 5 features
- **Recommended Intervention Type**: Phone, SMS, Email
- **Estimated Time to Close**: Days to closure

### Example Prediction

```python
prediction = {
    'closure_probability': 75.3,
    'confidence_interval_lower': 70.1,
    'confidence_interval_upper': 80.5,
    'recommended_intervention': 'Phone',
    'estimated_days_to_close': 14,
    'influencing_factors': [
        {'feature': 'prior_year_compliance', 'importance': 0.15},
        {'feature': 'outreach_response_rate', 'importance': 0.12},
        ...
    ]
}
```

## Implementation

### Batch Predictions

Run nightly batch predictions:

```python
from utils.ml_prediction_service import GapClosurePredictionService

service = GapClosurePredictionService(model_path='models/gap_closure_model.pkl')

predictions = service.predict_batch(
    gaps=gaps_list,
    member_data_dict=member_data,
    engagement_data_dict=engagement_data,
    operational_data=operational_data
)
```

### Real-Time Scoring

Real-time API for single predictions:

```python
prediction = service.predict_single(
    member_id='MEM001',
    gap_data=gap_data,
    member_data=member_data,
    engagement_data=engagement_data,
    operational_data=operational_data
)
```

### Model Monitoring

- **Performance Metrics**: Track accuracy, precision, recall over time
- **Drift Detection**: Monitor feature distributions
- **Prediction Distribution**: Track prediction buckets
- **Success Rate by Bucket**: Validate calibration

### Monthly Retraining

1. Collect new data
2. Retrain model
3. Evaluate performance
4. Deploy if improved
5. A/B test if significant changes

## Dashboard

### Model Performance Metrics

- Overall accuracy, precision, recall, F1
- ROC AUC score
- Confusion matrix
- Cross-validation scores

### Feature Importance

- Top 20 features visualization
- Feature importance scores
- Feature contribution analysis

### Prediction Distribution

- Distribution by probability bucket
- Success rate by bucket
- Calibration analysis

### ROI Analysis

- Efficiency gain with ML
- Cost savings
- Comparison vs random outreach

## Mobile Integration

### Member Cards

- Show prediction score
- Color-coded likelihood badges:
  - Green: High (â‰¥75%)
  - Yellow: Medium (50-74%)
  - Orange: Low (<50%)

### Intervention Recommendations

- Display recommended intervention type
- Show estimated time to close
- Highlight key influencing factors

## Best Practices

1. **Regular Retraining**: Monthly retraining with new data
2. **Monitor Performance**: Track metrics continuously
3. **Detect Drift**: Monitor feature distributions
4. **A/B Testing**: Test model improvements
5. **Calibration**: Ensure probabilities are well-calibrated

## Troubleshooting

### Low Accuracy

- Check feature quality
- Review class imbalance handling
- Increase training data
- Tune hyperparameters

### Drift Detected

- Investigate feature changes
- Retrain model
- Update feature engineering
- Review data pipeline

### Poor Calibration

- Adjust probability thresholds
- Use calibration techniques
- Review success rates by bucket
- Retrain with balanced data

## Next Steps

1. **Train Model**: Run training script with historical data
2. **Deploy Model**: Load model in prediction service
3. **Integrate**: Add to workflow and mobile app
4. **Monitor**: Set up monitoring and alerts
5. **Iterate**: Retrain monthly and improve

## Support

For questions or issues:
- ðŸ“§ **Email**: reichert.starguardai@gmail.com
- ðŸ”— **LinkedIn**: [sentinel-analytics](https://www.linkedin.com/in/sentinel-analytics/)
- ðŸ’» **GitHub**: [HEDIS-MA-Top-12-w-HEI-Prep](https://github.com/StarGuardAi/HEDIS-MA-Top-12-w-HEI-Prep/blob/main/README.md)
- ðŸŽ¨ **Portfolio**: [Canva Portfolio](https://www.canva.com/design/DAG2WzhiLwM/N_iXUe3eEKL3dzQ2M_0PgQ/edit)

---

**ML Gap Closure Predictions** | XGBoost/Random Forest | Real-time Scoring

